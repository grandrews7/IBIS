{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "497c6f76-4065-4460-99c3-449d6f7a76e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-01T11:04:05.489228Z",
     "iopub.status.busy": "2024-10-01T11:04:05.489005Z",
     "iopub.status.idle": "2024-10-01T11:04:15.542691Z",
     "shell.execute_reply": "2024-10-01T11:04:15.541796Z",
     "shell.execute_reply.started": "2024-10-01T11:04:05.489200Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.layers import Input, Lambda, Conv1D, maximum, GlobalMaxPooling1D, Dense, GaussianNoise, MaxPooling1D, Flatten, BatchNormalization\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.constraints import non_neg\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import logomaker\n",
    "\n",
    "import random\n",
    "from tqdm import trange\n",
    "from subprocess import Popen, PIPE, run\n",
    "import sys\n",
    "import pickle\n",
    "from pyfaidx import Fasta\n",
    "from  tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import random\n",
    "import glob\n",
    "import bioframe\n",
    "import os\n",
    "import tempfile\n",
    "from collections import Counter\n",
    "from sklearn.utils import shuffle\n",
    "import gzip\n",
    "import tqdm\n",
    "import sys\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dce66087-fa31-4836-a096-54d3753e5a74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-01T11:04:16.266007Z",
     "iopub.status.busy": "2024-10-01T11:04:16.265772Z",
     "iopub.status.idle": "2024-10-01T11:04:16.284772Z",
     "shell.execute_reply": "2024-10-01T11:04:16.284193Z",
     "shell.execute_reply.started": "2024-10-01T11:04:16.265976Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow_core/python/keras/initializers.py:143: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "#Models\n",
    "def construct_model(num_kernels=32,\n",
    "                    kernel_width=24,\n",
    "                    seq_len=None,\n",
    "                    dropout_prop=0.0,\n",
    "                    use_bias=False,\n",
    "                    kernel_initializer=initializers.RandomNormal(stddev=0.0001, seed=12),\n",
    "                    optimizer='adam',\n",
    "                    activation='linear',\n",
    "                    num_classes=1,\n",
    "                    l1_reg=0.0,\n",
    "                    l2_reg= 0.0,\n",
    "                    gaussian_noise = 0.1,\n",
    "                    spatial_dropout = 0.0,\n",
    "                    rc = True,\n",
    "                    padding=\"same\",\n",
    "                    conv_name=\"shared_conv\"):\n",
    "    if rc:\n",
    "        seq_input = Input(shape=(seq_len,4))\n",
    "        rc_op = Lambda(lambda x: K.reverse(x,axes=(1,2)))\n",
    "        seq_rc = rc_op(seq_input)\n",
    "        if gaussian_noise > 0.0:\n",
    "            noisy_seq = GaussianNoise(gaussian_noise)(seq_input)\n",
    "            noisy_seq_rc = rc_op(noisy_seq)\n",
    "        \n",
    "        shared_conv = Conv1D(num_kernels, kernel_width,\n",
    "                             strides=1,\n",
    "                             padding=padding, \n",
    "                             activation=activation,\n",
    "                             use_bias=use_bias,\n",
    "                             kernel_initializer=kernel_initializer,\n",
    "                             kernel_regularizer=regularizers.l1_l2(l1=l1_reg,\n",
    "                                                                   l2=l2_reg),\n",
    "                             bias_initializer='zeros',\n",
    "                             name=conv_name)\n",
    "\n",
    "        if gaussian_noise > 0:\n",
    "            conv_for = shared_conv(noisy_seq)\n",
    "            conv_rc = shared_conv(noisy_seq_rc)\n",
    "        else:\n",
    "            conv_for = shared_conv(seq_input)\n",
    "            conv_rc = shared_conv(seq_rc)\n",
    "            \n",
    "\n",
    "        merged = maximum([conv_for, conv_rc])\n",
    "        pooled = GlobalMaxPooling1D()(merged)\n",
    "        if dropout_prop > 0.0:\n",
    "            dropout = Dropout(dropout_prop)(pooled)\n",
    "            output = Dense(1, activation='sigmoid',\n",
    "                       use_bias=True,\n",
    "                       kernel_initializer=initializers.RandomUniform(minval=0.0, maxval=0.001, seed=12), \n",
    "                       kernel_constraint=non_neg(), \n",
    "                       bias_initializer='zeros',\n",
    "                       name=\"dense_1\")(dropout)\n",
    "        else:\n",
    "            output = Dense(1, activation='sigmoid',\n",
    "                           use_bias=True,\n",
    "                           kernel_initializer=initializers.RandomUniform(minval=0.0, maxval=0.001, seed=12), \n",
    "                           kernel_constraint=non_neg(), \n",
    "                           bias_initializer='zeros',\n",
    "                           name=\"dense_1\")(pooled)\n",
    "        model = Model(inputs=seq_input, outputs=output)\n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        model.summary()\n",
    "        return model\n",
    "\n",
    "\n",
    "\n",
    "def construct_scan_model(conv_weights):\n",
    "    kernel_width = conv_weights.shape[0]\n",
    "    num_kernels = conv_weights.shape[2]\n",
    "    seq = Input(shape=(None,4))\n",
    "    conv = Conv1D(num_kernels, kernel_width, \n",
    "                  name = 'scan_conv',\n",
    "                  strides=1, \n",
    "                  padding='valid', \n",
    "                  activation='linear', \n",
    "                  use_bias=False, \n",
    "                  kernel_initializer='zeros', \n",
    "                  bias_initializer='zeros',\n",
    "                  trainable=False)\n",
    "    \n",
    "    conv_seq = conv(seq)\n",
    "    \n",
    "    \n",
    "    model = Model(inputs=seq, outputs=conv_seq)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.get_layer('scan_conv').set_weights([conv_weights])\n",
    "    return model\n",
    "\n",
    "\n",
    "def construct_score_model(conv_weights):\n",
    "    kernel_width = conv_weights.shape[0]\n",
    "    num_kernels = conv_weights.shape[2]\n",
    "    seq = Input(shape=(None,4))\n",
    "    rc_op = Lambda(lambda x: K.reverse(x,axes=(1,2)))\n",
    "    seq_rc = rc_op(seq)\n",
    "    \n",
    "    conv = Conv1D(num_kernels, kernel_width, \n",
    "                  name = 'score_conv',\n",
    "                  strides=1, \n",
    "                  padding='valid', \n",
    "                  activation='linear', \n",
    "                  use_bias=use_bias, \n",
    "                  kernel_initializer='zeros', \n",
    "                  bias_initializer='zeros',\n",
    "                  trainable=False)\n",
    "    \n",
    "    conv_for = conv(seq)\n",
    "    conv_rc = conv(seq_rc)\n",
    "    \n",
    "    merged = maximum([conv_for, conv_rc])\n",
    "    pooled = GlobalMaxPooling1D()(merged)\n",
    "    model = Model(inputs=seq, outputs=pooled)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.get_layer(\"score_conv\").set_weights([conv_weights])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2a24514-8408-4aa0-b633-2f761a277a25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-01T11:04:27.560628Z",
     "iopub.status.busy": "2024-10-01T11:04:27.560432Z",
     "iopub.status.idle": "2024-10-01T11:04:27.579835Z",
     "shell.execute_reply": "2024-10-01T11:04:27.579301Z",
     "shell.execute_reply.started": "2024-10-01T11:04:27.560603Z"
    }
   },
   "outputs": [],
   "source": [
    "# P. Clote, Oct 2003\n",
    "\n",
    "def computeCountAndLists(s):\n",
    "\n",
    "    #Initialize lists and mono- and dinucleotide dictionaries\n",
    "    List = {} #List is a dictionary of lists\n",
    "    List['A'] = []; List['C'] = [];\n",
    "    List['G'] = []; List['T'] = [];\n",
    "    # FIXME: is this ok?\n",
    "    List['N'] = []\n",
    "    nuclList   = [\"A\",\"C\",\"G\",\"T\",\"N\"]\n",
    "    s       = s.upper()\n",
    "    #s       = s.replace(\"U\",\"T\")\n",
    "    nuclCnt    = {}  #empty dictionary\n",
    "    dinuclCnt  = {}  #empty dictionary\n",
    "    for x in nuclList:\n",
    "        nuclCnt[x]=0\n",
    "        dinuclCnt[x]={}\n",
    "        for y in nuclList:\n",
    "            dinuclCnt[x][y]=0\n",
    "\n",
    "    #Compute count and lists\n",
    "    nuclCnt[s[0]] = 1\n",
    "    nuclTotal     = 1\n",
    "    dinuclTotal   = 0\n",
    "    for i in range(len(s)-1):\n",
    "        x = s[i]; y = s[i+1]\n",
    "        List[x].append( y )\n",
    "        nuclCnt[y] += 1; nuclTotal  += 1\n",
    "        dinuclCnt[x][y] += 1; dinuclTotal += 1\n",
    "    assert (nuclTotal==len(s))\n",
    "    assert (dinuclTotal==len(s)-1)\n",
    "    return nuclCnt,dinuclCnt,List\n",
    "\n",
    "\n",
    "def chooseEdge(x,dinuclCnt):\n",
    "    z = random.random()\n",
    "    denom=dinuclCnt[x]['A']+dinuclCnt[x]['C']+dinuclCnt[x]['G']+dinuclCnt[x]['T']+dinuclCnt[x]['N']\n",
    "    numerator = dinuclCnt[x]['A']\n",
    "    if z < float(numerator)/float(denom):\n",
    "        dinuclCnt[x]['A'] -= 1\n",
    "        return 'A'\n",
    "    numerator += dinuclCnt[x]['C']\n",
    "    if z < float(numerator)/float(denom):\n",
    "        dinuclCnt[x]['C'] -= 1\n",
    "        return 'C'\n",
    "    numerator += dinuclCnt[x]['G']\n",
    "    if z < float(numerator)/float(denom):\n",
    "        dinuclCnt[x]['G'] -= 1\n",
    "        return 'G'\n",
    "    numerator += dinuclCnt[x]['T']\n",
    "    if z < float(numerator)/float(denom):\n",
    "        dinuclCnt[x]['T'] -= 1\n",
    "        return 'T'\n",
    "    dinuclCnt[x]['N'] -= 1\n",
    "    return 'N'\n",
    "\n",
    "def connectedToLast(edgeList,nuclList,lastCh):\n",
    "    D = {}\n",
    "    for x in nuclList: D[x]=0\n",
    "    for edge in edgeList:\n",
    "        a = edge[0]; b = edge[1]\n",
    "        if b==lastCh: D[a]=1\n",
    "    for i in range(3):\n",
    "        for edge in edgeList:\n",
    "            a = edge[0]; b = edge[1]\n",
    "            if D[b]==1: D[a]=1\n",
    "    ok = 0\n",
    "    for x in nuclList:\n",
    "        if x!=lastCh and D[x]==0: return 0\n",
    "    return 1\n",
    "\n",
    "def eulerian(s):\n",
    "    nuclCnt,dinuclCnt,List = computeCountAndLists(s)\n",
    "    #compute nucleotides appearing in s\n",
    "    nuclList = []\n",
    "    for x in [\"A\",\"C\",\"G\",\"T\",\"N\"]:\n",
    "        if x in s: nuclList.append(x)\n",
    "    #create dinucleotide shuffle L\n",
    "    firstCh = s[0]  #start with first letter of s\n",
    "    lastCh  = s[-1]\n",
    "    edgeList = []\n",
    "    for x in nuclList:\n",
    "        if x!= lastCh: edgeList.append( [x,chooseEdge(x,dinuclCnt)] )\n",
    "    ok = connectedToLast(edgeList,nuclList,lastCh)\n",
    "    return ok,edgeList,nuclList,lastCh\n",
    "\n",
    "\n",
    "def shuffleEdgeList(L):\n",
    "    n = len(L); barrier = n\n",
    "    for i in range(n-1):\n",
    "        z = int(random.random() * barrier)\n",
    "        tmp = L[z]\n",
    "        L[z]= L[barrier-1]\n",
    "        L[barrier-1] = tmp\n",
    "        barrier -= 1\n",
    "    return L\n",
    "\n",
    "def dinuclShuffle(s):\n",
    "    ok = 0\n",
    "    while not ok:\n",
    "        ok,edgeList,nuclList,lastCh = eulerian(s)\n",
    "    nuclCnt,dinuclCnt,List = computeCountAndLists(s)\n",
    "\n",
    "    #remove last edges from each vertex list, shuffle, then add back\n",
    "    #the removed edges at end of vertex lists.\n",
    "    for [x,y] in edgeList: List[x].remove(y)\n",
    "    for x in nuclList: shuffleEdgeList(List[x])\n",
    "    for [x,y] in edgeList: List[x].append(y)\n",
    "\n",
    "    #construct the eulerian path\n",
    "    L = [s[0]]; prevCh = s[0]\n",
    "    for i in range(len(s)-2):\n",
    "        ch = List[prevCh][0]\n",
    "        L.append( ch )\n",
    "        del List[prevCh][0]\n",
    "        prevCh = ch\n",
    "    L.append(s[-1])\n",
    "    #t = string.join(L,\"\")\n",
    "    t = \"\".join(L)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "566cfc97-5802-4c1b-a51e-799cad8c6b0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-01T11:04:35.492991Z",
     "iopub.status.busy": "2024-10-01T11:04:35.492792Z",
     "iopub.status.idle": "2024-10-01T11:04:35.500071Z",
     "shell.execute_reply": "2024-10-01T11:04:35.499507Z",
     "shell.execute_reply.started": "2024-10-01T11:04:35.492965Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_information_content(x):\n",
    "    ic = x * np.log2((x + .001) / .25)\n",
    "    if ic > 0:\n",
    "        return(ic)\n",
    "    else:\n",
    "        return(0.0)\n",
    "    \n",
    "def get_info_content(ppm):\n",
    "    w = ppm.shape[0]\n",
    "    info = np.zeros(w)\n",
    "    for i in range(w):\n",
    "        for j in range(4):\n",
    "            info[i] += ppm[i,j] * np.log2((ppm[i,j] + .001) / 0.25)\n",
    "    return(info)\n",
    "    \n",
    "def trim_ppm(ppm, min_info=0.0):\n",
    "    info = get_info_content(ppm)\n",
    "    start_index = 0\n",
    "    w = ppm.shape[0]\n",
    "    stop_index = w\n",
    "    for i in range(w):\n",
    "        if info[i] < min_info:\n",
    "            start_index += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    for i in range(w):\n",
    "        if info[w-i-1] < 0.25:\n",
    "            stop_index -= 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    if np.max(info) < 0.25:\n",
    "        return(ppm, 0, w)\n",
    "    else:\n",
    "        return(ppm[start_index:stop_index,:], start_index, stop_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b1ec541-b340-4148-ab86-95280c9bd2d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-01T11:04:42.152499Z",
     "iopub.status.busy": "2024-10-01T11:04:42.152325Z",
     "iopub.status.idle": "2024-10-01T11:04:42.159423Z",
     "shell.execute_reply": "2024-10-01T11:04:42.158851Z",
     "shell.execute_reply.started": "2024-10-01T11:04:42.152475Z"
    }
   },
   "outputs": [],
   "source": [
    "DNA_SEQ_DICT = {\n",
    "    'A' : [1, 0, 0, 0],\n",
    "    'C' : [0, 1, 0, 0],\n",
    "    'G' : [0, 0, 1, 0],\n",
    "    'T' : [0, 0, 0, 1],\n",
    "}\n",
    "\n",
    "def encode_sequence(seq, N = [0, 0, 0, 0], seq_dict = None, useN = None):\n",
    "    if seq_dict is None:\n",
    "        seq_dict = DNA_SEQ_DICT\n",
    "    if useN == 'uniform':\n",
    "        N = [(1/len(seq_dict)) for _ in seq_dict]\n",
    "    elif useN == 'zeros':\n",
    "        N = [0 for _ in seq_dict]\n",
    "    d = { **seq_dict, 'N' : N }\n",
    "    return np.array([d[nuc] for nuc in list(seq)]).astype('float32')\n",
    " \n",
    "def decode_sequence(encoded_seq, seq_dict = None):\n",
    "    if seq_dict is None:\n",
    "        seq_dict = DNA_SEQ_DICT\n",
    "    seq_list = encoded_seq.astype('int').tolist()\n",
    "    def decode_base(encoded_base):\n",
    "        for letter,onehot in seq_dict.items():\n",
    "            if np.array_equal(encoded_base, onehot):\n",
    "                return letter\n",
    "        return \"N\"\n",
    "    return \"\".join(decode_base(b) for b in encoded_seq.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "875247d2-9421-43b3-9cca-7f0e09fc7041",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-01T11:04:55.361397Z",
     "iopub.status.busy": "2024-10-01T11:04:55.361179Z",
     "iopub.status.idle": "2024-10-01T11:04:55.377927Z",
     "shell.execute_reply": "2024-10-01T11:04:55.377350Z",
     "shell.execute_reply.started": "2024-10-01T11:04:55.361372Z"
    }
   },
   "outputs": [],
   "source": [
    "from  tensorflow.keras.callbacks import Callback\n",
    "class SGDRScheduler(Callback):\n",
    "    '''Cosine annealing learning rate scheduler with periodic restarts.\n",
    "\n",
    "    # Usage\n",
    "        ```python\n",
    "            schedule = SGDRScheduler(min_lr=1e-5,\n",
    "                                     max_lr=1e-2,\n",
    "                                     steps_per_epoch=np.ceil(epoch_size/batch_size),\n",
    "                                     lr_decay=0.9,\n",
    "                                     cycle_length=5,\n",
    "                                     mult_factor=1.5)\n",
    "            model.fit(X_train, Y_train, epochs=100, callbacks=[schedule])\n",
    "        ```\n",
    "\n",
    "    # Arguments\n",
    "        min_lr: The lower bound of the learning rate range for the experiment.\n",
    "        max_lr: The upper bound of the learning rate range for the experiment.\n",
    "        steps_per_epoch: Number of mini-batches in the dataset. Calculated as `np.ceil(epoch_size/batch_size)`. \n",
    "        lr_decay: Reduce the max_lr after the completion of each cycle.\n",
    "                  Ex. To reduce the max_lr by 20% after each cycle, set this value to 0.8.\n",
    "        cycle_length: Initial number of epochs in a cycle.\n",
    "        mult_factor: Scale epochs_to_restart after each full cycle completion.\n",
    "\n",
    "    # References\n",
    "        Blog post: jeremyjordan.me/nn-learning-rate\n",
    "        Original paper: http://arxiv.org/abs/1608.03983\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 min_lr,\n",
    "                 max_lr,\n",
    "                 steps_per_epoch,\n",
    "                 lr_decay=1,\n",
    "                 cycle_length=10,\n",
    "                 mult_factor=2,\n",
    "                 shape=\"cosine\"):\n",
    "\n",
    "        self.min_lr = min_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.lr_decay = lr_decay\n",
    "\n",
    "        self.batch_since_restart = 0\n",
    "        self.next_restart = cycle_length\n",
    "\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "\n",
    "        self.cycle_length = cycle_length\n",
    "        self.mult_factor = mult_factor\n",
    "        \n",
    "        self.shape = shape\n",
    "        self.history = {}\n",
    "        self.learning_rates = []\n",
    "\n",
    "    def clr(self):\n",
    "        '''Calculate the learning rate.'''\n",
    "        fraction_to_restart = self.batch_since_restart / (self.steps_per_epoch * self.cycle_length)\n",
    "        #print(fraction_to_restart)\n",
    "        if self.shape == \"cosine\":\n",
    "            lr = self.min_lr + 0.5 * (self.max_lr - self.min_lr) * (1 + np.cos(fraction_to_restart * np.pi))\n",
    "        else:\n",
    "            if fraction_to_restart < 0.5:\n",
    "                lr = fraction_to_restart * (self.max_lr - self.min_lr) / 0.5 + self.min_lr\n",
    "            else:\n",
    "                lr = (1 - fraction_to_restart) * (self.max_lr - self.min_lr) / 0.5 + self.min_lr\n",
    "        self.learning_rates.append(lr)\n",
    "        return lr\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        '''Initialize the learning rate to the minimum value at the start of training.'''\n",
    "        logs = logs or {}\n",
    "        if self.shape == \"cosine\":\n",
    "            K.set_value(self.model.optimizer.lr, self.max_lr)\n",
    "        else:\n",
    "            K.set_value(self.model.optimizer.lr, self.min_lr)\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        '''Record previous batch statistics and update the learning rate.'''\n",
    "        logs = logs or {}\n",
    "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "\n",
    "        self.batch_since_restart += 1\n",
    "        K.set_value(self.model.optimizer.lr, self.clr())\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        '''Check for end of current cycle, apply restarts when necessary.'''\n",
    "        if epoch + 1 == self.next_restart:\n",
    "            self.batch_since_restart = 0\n",
    "            self.cycle_length = np.ceil(self.cycle_length * self.mult_factor)\n",
    "            self.next_restart += self.cycle_length\n",
    "            self.max_lr *= self.lr_decay\n",
    "            self.best_weights = self.model.get_weights()\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        '''Set weights to the values from the end of the most recent cycle for best performance.'''\n",
    "        self.model.set_weights(self.best_weights)\n",
    "        \n",
    "class SWA(Callback):\n",
    "\n",
    "    def __init__(self, epochs_to_train, prop = 0.2, interval = 1):\n",
    "        super(SWA, self).__init__()\n",
    "        self.epochs_to_train = epochs_to_train\n",
    "        self.prop = prop\n",
    "        self.interval = interval\n",
    "        self.n_models = 0\n",
    "        self.epoch = 0\n",
    "        \n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.nb_epoch = self.params['epochs']\n",
    "        self.weights = []\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.epoch += 1\n",
    "        if epoch % self.interval == 0:\n",
    "            self.weights.append(self.model.get_weights())\n",
    "            self.n_models += 1\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        num_models_to_average = int(np.ceil(self.prop * self.epoch))\n",
    "        new_weights = list()\n",
    "        for weights_list_tuple in zip(*self.weights[-num_models_to_average:]): \n",
    "            new_weights.append(\n",
    "                np.array([np.array(w).mean(axis=0) for w in zip(*weights_list_tuple)])\n",
    "            )\n",
    "        self.model.set_weights(new_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6773dd6-0fec-4722-b42a-d0e43d1c4d73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-01T11:05:08.769683Z",
     "iopub.status.busy": "2024-10-01T11:05:08.769450Z",
     "iopub.status.idle": "2024-10-01T11:05:08.781490Z",
     "shell.execute_reply": "2024-10-01T11:05:08.780890Z",
     "shell.execute_reply.started": "2024-10-01T11:05:08.769655Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_rc(re):\n",
    "    \"\"\"\n",
    "    Return the reverse complement of a DNA/RNA RE.\n",
    "    \"\"\"\n",
    "    return re.translate(str.maketrans('ACGTURYKMBVDHSWN', 'TGCAAYRMKVBHDSWN'))[::-1]\n",
    "\n",
    "\n",
    "def count_seqs_with_words(seqs, halflength, ming, maxg, alpha, revcomp, desc):\n",
    "    if alpha == 'protein':\n",
    "        ambiguous_character = 'X'\n",
    "    else:\n",
    "        ambiguous_character = 'N'\n",
    "    gapped_kmer_dict = {}  # each key is the gapped k-mer word\n",
    "    for g in trange(ming, maxg + 1, 1, desc=desc):\n",
    "        w = g+2*halflength # length of the word\n",
    "        gap = g * ambiguous_character\n",
    "        for seq in seqs:\n",
    "            slen = len(seq)\n",
    "            for i in range(0, slen-w+1):\n",
    "                word = seq[i : i+w]\n",
    "                # skip word if it contains an ambiguous character\n",
    "                if ambiguous_character in word:\n",
    "                    continue\n",
    "                # convert word to a gapped word. Only the first and last half-length letters are preserved\n",
    "                word = word[0:halflength] + gap + word[-halflength:]\n",
    "                update_gapped_kmer_dict(gapped_kmer_dict, word, revcomp)\n",
    "    return gapped_kmer_dict\n",
    "\n",
    "\n",
    "def update_gapped_kmer_dict(gapped_kmer_dict, word, revcomp):\n",
    "    # use the lower alphabet word for rc\n",
    "    if revcomp:\n",
    "        word = min(word, get_rc(word))\n",
    "    if word in gapped_kmer_dict:  # word has been encountered before, add 1\n",
    "        gapped_kmer_dict[word] += 1\n",
    "    else:  # word has not been encountered before, create new key\n",
    "        gapped_kmer_dict[word] = 1\n",
    "\n",
    "\n",
    "def get_zscores(pos_seq_counts, neg_seq_counts):\n",
    "    zscores_dict = {}\n",
    "    for word in pos_seq_counts:\n",
    "        p = pos_seq_counts[word]\n",
    "        if word in neg_seq_counts:\n",
    "            n = neg_seq_counts[word]\n",
    "        else:\n",
    "            n = 1\n",
    "        zscore = 1.0*(p - n)/np.sqrt(n)\n",
    "        zscores_dict[word] = zscore\n",
    "    return zscores_dict\n",
    "\n",
    "\n",
    "# returns the words in order, from largest to smallest, by z-scores\n",
    "def sorted_zscore_keys(zscores_dict):\n",
    "    sorted_keys = sorted(zscores_dict, key=zscores_dict.__getitem__, reverse=True)\n",
    "    return sorted_keys\n",
    "\n",
    "\n",
    "def find_n_top_words(zscores_dict, num_find):\n",
    "    keys = np.array(list(zscores_dict.keys()))\n",
    "    values = np.array(list(zscores_dict.values()))\n",
    "    ind = np.argpartition(values, -num_find)[-num_find:]\n",
    "    top_words = list(keys[ind])\n",
    "    return top_words\n",
    "\n",
    "\n",
    "def find_enriched_gapped_kmers(pos_seqs, neg_seqs, halflength, ming, maxg, alpha, revcomp, num_find):\n",
    "    pos_seq_counts = count_seqs_with_words(pos_seqs, halflength, ming, maxg, alpha, revcomp,\n",
    "                                           'Searching positive sequences')\n",
    "    neg_seq_counts = count_seqs_with_words(neg_seqs, halflength, ming, maxg, alpha, revcomp,\n",
    "                                           'Searching negative sequences')\n",
    "    zscores = get_zscores(pos_seq_counts,neg_seq_counts)\n",
    "    top_words = find_n_top_words(zscores, num_find)\n",
    "    return top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "351a4b1f-8407-4c42-a324-d35870141e56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-01T11:05:15.027020Z",
     "iopub.status.busy": "2024-10-01T11:05:15.026822Z",
     "iopub.status.idle": "2024-10-01T11:05:15.030274Z",
     "shell.execute_reply": "2024-10-01T11:05:15.029725Z",
     "shell.execute_reply.started": "2024-10-01T11:05:15.026992Z"
    }
   },
   "outputs": [],
   "source": [
    "def ppm_to_pwm(ppm):\n",
    "    pwm = ppm + 1e-5\n",
    "    pwm = pwm / 0.25\n",
    "    pwm = np.log2(pwm)\n",
    "    return(pwm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1fbce72-7ce3-4f49-9208-a9bc12eb2ee8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-01T11:05:23.251120Z",
     "iopub.status.busy": "2024-10-01T11:05:23.250924Z",
     "iopub.status.idle": "2024-10-01T11:05:23.258831Z",
     "shell.execute_reply": "2024-10-01T11:05:23.258260Z",
     "shell.execute_reply.started": "2024-10-01T11:05:23.251095Z"
    }
   },
   "outputs": [],
   "source": [
    "class dataGen(Sequence):\n",
    "    def __init__(self, posSeqs, \n",
    "                 negSeqs=None,\n",
    "                 batchSize = 32,\n",
    "                 seqsPerEpoch=20000,\n",
    "                 padBy = 24):\n",
    "        \n",
    "        self.posSeqs = posSeqs\n",
    "        self.L = np.max([len(x) for x in self.posSeqs])\n",
    "        print(\"Maximum sequence length = {}\".format(self.L))\n",
    "        \n",
    "        self.batchSize = batchSize\n",
    "        self.b2 = self.batchSize // 2\n",
    "        self.seqsPerEpoch = seqsPerEpoch\n",
    "        self.padBy = padBy\n",
    "        \n",
    "        self.labels = np.array([1 for i in range(self.b2)] + [0 for i in range(self.b2)])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return(int(np.floor(self.seqsPerEpoch / self.batchSize)))\n",
    "\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        posSample = random.sample(self.posSeqs, self.b2)\n",
    "        negSample = [dinuclShuffle(_) for _ in posSample]\n",
    "            \n",
    "        X = 0.25 * np.ones((self.batchSize, 2*self.padBy + self.L, 4))\n",
    "            \n",
    "        for i,seq in enumerate(posSample + negSample):\n",
    "            l = len(seq)\n",
    "            start = self.padBy + (self.L - l) // 2\n",
    "            stop = start + l\n",
    "            X[i,start:stop,:] = encode_sequence(seq)\n",
    "            \n",
    "        return(X, self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7da04e2-9e40-47a7-8695-7d0a3605505a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-01T11:08:56.293761Z",
     "iopub.status.busy": "2024-10-01T11:08:56.293540Z",
     "iopub.status.idle": "2024-10-01T11:08:56.299351Z",
     "shell.execute_reply": "2024-10-01T11:08:56.298573Z",
     "shell.execute_reply.started": "2024-10-01T11:08:56.293735Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FASTQ files:\n",
      " ../data//HTS/NFKB1/NFKB1_R0_C4_lf5ACGACGCTCTTCCGATCTAC_rf3GCTGCTAGATCGGAAGAGCA.fastq.gz\n"
     ]
    }
   ],
   "source": [
    "TF = \"NFKB1\"\n",
    "cycle = \"C4\"\n",
    "output_dir = \"../demo/\"\n",
    "data_dir = \"../data/\"\n",
    "data_dir = \"{}/HTS/{}/\".format(data_dir, TF)\n",
    "dataFiles = glob.glob(data_dir + TF + \"_*_\" + cycle + \"*\")\n",
    "print(\"FASTQ files:\\n\", *dataFiles)\n",
    "n_kmers = 1\n",
    "w = 30\n",
    "n_motifs = 1\n",
    "if n_kmers > n_motifs:\n",
    "    n_kmers = n_motifs\n",
    "use_bias = True\n",
    "epochs = 10\n",
    "l2 = 0.00001\n",
    "l1 = 0.00001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "962bfa97-f36f-4b77-b99d-7ef56a48ad20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-01T11:07:24.907771Z",
     "iopub.status.busy": "2024-10-01T11:07:24.907567Z",
     "iopub.status.idle": "2024-10-01T11:07:26.319233Z",
     "shell.execute_reply": "2024-10-01T11:07:26.318563Z",
     "shell.execute_reply.started": "2024-10-01T11:07:24.907746Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 206609 total sequences\n"
     ]
    }
   ],
   "source": [
    "seqs = []\n",
    "for fastq in dataFiles:\n",
    "    with gzip.open(fastq) as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i % 4 == 1:\n",
    "                seqs.append(str(line, encoding=\"utf-8\").strip().split()[0])\n",
    "\n",
    "print(\"There are {} total sequences\".format(len(seqs)))\n",
    "n = len(seqs)\n",
    "random.shuffle(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c22d75c9-5cef-42c8-ab7c-405851386b92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-01T11:07:34.718130Z",
     "iopub.status.busy": "2024-10-01T11:07:34.717915Z",
     "iopub.status.idle": "2024-10-01T11:07:38.966126Z",
     "shell.execute_reply": "2024-10-01T11:07:38.965463Z",
     "shell.execute_reply.started": "2024-10-01T11:07:34.718104Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding enriched gapped kmers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching positive sequences: 100%|██████████| 19/19 [00:01<00:00, 12.16it/s]\n",
      "Searching negative sequences: 100%|██████████| 19/19 [00:01<00:00, 12.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enriched kmers...\n",
      "\tGGGNNNNCCC\n"
     ]
    }
   ],
   "source": [
    "if n_kmers > 0:\n",
    "    print(\"Finding enriched gapped kmers\")\n",
    "    tmpPosSeqs = seqs[:5000]\n",
    "    kmers = find_enriched_gapped_kmers(tmpPosSeqs, [dinuclShuffle(_) for _ in tmpPosSeqs],  3, 0, 18, \"dna\", False, n_kmers)\n",
    "print(\"Enriched kmers...\\n\" + \"\\n\".join([\"\\t\" + _ for _ in kmers[::-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2963718e-6371-4252-9e5c-47d986a86ca4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-01T11:07:43.113406Z",
     "iopub.status.busy": "2024-10-01T11:07:43.113166Z",
     "iopub.status.idle": "2024-10-01T11:07:43.175098Z",
     "shell.execute_reply": "2024-10-01T11:07:43.174554Z",
     "shell.execute_reply.started": "2024-10-01T11:07:43.113378Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sequence length = 40\n",
      "Maximum sequence length = 40\n"
     ]
    }
   ],
   "source": [
    "holdOutP = .1\n",
    "n = len(seqs)\n",
    "\n",
    "\n",
    "trainGen = dataGen(seqs[:int((1 - holdOutP)*n)],\n",
    "                   seqsPerEpoch=5000, \n",
    "                   padBy=w)\n",
    "testGen = dataGen(seqs[int((1 - holdOutP)*n):],\n",
    "                  seqsPerEpoch=1000, padBy=w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5dd01abb-1300-47c1-a21e-b1a4fe9d0beb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-01T11:07:56.723126Z",
     "iopub.status.busy": "2024-10-01T11:07:56.722909Z",
     "iopub.status.idle": "2024-10-01T11:07:56.889976Z",
     "shell.execute_reply": "2024-10-01T11:07:56.889432Z",
     "shell.execute_reply.started": "2024-10-01T11:07:56.723099Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, None, 4)      0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, None, 4)      0           gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "shared_conv (Conv1D)            (None, None, 1)      121         gaussian_noise[0][0]             \n",
      "                                                                 lambda[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "maximum (Maximum)               (None, None, 1)      0           shared_conv[0][0]                \n",
      "                                                                 shared_conv[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 1)            0           maximum[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            2           global_max_pooling1d[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 123\n",
      "Trainable params: 123\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "use_bias = True\n",
    "model = construct_model(num_kernels=n_motifs,\n",
    "                        kernel_width=w,\n",
    "                        use_bias=use_bias, \n",
    "                        l2_reg=l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97719c9f-4ce0-4af7-b2a9-7b304edecbb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-01T11:08:08.119844Z",
     "iopub.status.busy": "2024-10-01T11:08:08.119626Z",
     "iopub.status.idle": "2024-10-01T11:08:08.288924Z",
     "shell.execute_reply": "2024-10-01T11:08:08.288347Z",
     "shell.execute_reply.started": "2024-10-01T11:08:08.119817Z"
    }
   },
   "outputs": [],
   "source": [
    "if n_kmers > 0:\n",
    "    if use_bias:\n",
    "        conv_weights, conv_bias = model.get_layer(\"shared_conv\").get_weights()\n",
    "    else:\n",
    "        conv_weights = model.get_layer(\"shared_conv\").get_weights()[0]\n",
    "\n",
    "\n",
    "    for i in range(n_kmers):\n",
    "        kmer = kmers[i]\n",
    "        l = len(kmer)\n",
    "        conv_weights[((w - l)//2):(((w - l)//2)+l),:,i] = encode_sequence(kmer)\n",
    "\n",
    "\n",
    "    if use_bias:\n",
    "        model.get_layer(\"shared_conv\").set_weights([conv_weights, conv_bias])\n",
    "    else:\n",
    "        model.get_layer(\"shared_conv\").set_weights([conv_weights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80a7bcbf-e71d-499c-b7bd-c0274d42500c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-01T11:08:39.925076Z",
     "iopub.status.busy": "2024-10-01T11:08:39.924871Z",
     "iopub.status.idle": "2024-10-01T11:08:39.929022Z",
     "shell.execute_reply": "2024-10-01T11:08:39.928426Z",
     "shell.execute_reply.started": "2024-10-01T11:08:39.925048Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_lr = .001\n",
    "max_lr = .1\n",
    "lr_decay = (min_lr / max_lr) ** (1 / epochs)\n",
    "schedule = SGDRScheduler(min_lr=min_lr,\n",
    "                             max_lr=max_lr,\n",
    "                             steps_per_epoch=trainGen.__len__(),\n",
    "                             lr_decay=lr_decay,\n",
    "                             cycle_length=1,\n",
    "                             mult_factor=1.0, \n",
    "                             shape=\"triangular\")\n",
    "\n",
    "swa = SWA(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d592a27d-c46f-42f8-8033-45e48f6d18be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-01T11:09:01.570238Z",
     "iopub.status.busy": "2024-10-01T11:09:01.570015Z",
     "iopub.status.idle": "2024-10-01T11:09:17.366747Z",
     "shell.execute_reply": "2024-10-01T11:09:17.366083Z",
     "shell.execute_reply.started": "2024-10-01T11:09:01.570211Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "151/156 [============================>.] - ETA: 0s - loss: 0.1974 - acc: 0.9077Epoch 1/10\n",
      "156/156 [==============================] - 2s 13ms/step - loss: 0.1931 - acc: 0.9103 - val_loss: 0.0435 - val_acc: 0.9869\n",
      "Epoch 2/10\n",
      "149/156 [===========================>..] - ETA: 0s - loss: 0.0779 - acc: 0.9771Epoch 1/10\n",
      "156/156 [==============================] - 2s 10ms/step - loss: 0.0784 - acc: 0.9776 - val_loss: 0.0435 - val_acc: 0.9839\n",
      "Epoch 3/10\n",
      "149/156 [===========================>..] - ETA: 0s - loss: 0.0710 - acc: 0.9799Epoch 1/10\n",
      "156/156 [==============================] - 2s 10ms/step - loss: 0.0718 - acc: 0.9794 - val_loss: 0.0535 - val_acc: 0.9869\n",
      "Epoch 4/10\n",
      "148/156 [===========================>..] - ETA: 0s - loss: 0.0651 - acc: 0.9808Epoch 1/10\n",
      "156/156 [==============================] - 2s 10ms/step - loss: 0.0637 - acc: 0.9812 - val_loss: 0.0695 - val_acc: 0.9879\n",
      "Epoch 5/10\n",
      "151/156 [============================>.] - ETA: 0s - loss: 0.0624 - acc: 0.9816Epoch 1/10\n",
      "156/156 [==============================] - 2s 10ms/step - loss: 0.0636 - acc: 0.9820 - val_loss: 0.0405 - val_acc: 0.9899\n",
      "Epoch 6/10\n",
      "149/156 [===========================>..] - ETA: 0s - loss: 0.0743 - acc: 0.9776Epoch 1/10\n",
      "156/156 [==============================] - 2s 10ms/step - loss: 0.0737 - acc: 0.9782 - val_loss: 0.0746 - val_acc: 0.9849\n",
      "Epoch 7/10\n",
      "153/156 [============================>.] - ETA: 0s - loss: 0.0749 - acc: 0.9788Epoch 1/10\n",
      "156/156 [==============================] - 2s 10ms/step - loss: 0.0744 - acc: 0.9790 - val_loss: 0.0515 - val_acc: 0.9859\n",
      "Epoch 8/10\n",
      "153/156 [============================>.] - ETA: 0s - loss: 0.0620 - acc: 0.9833Epoch 1/10\n",
      "156/156 [==============================] - 1s 10ms/step - loss: 0.0619 - acc: 0.9834 - val_loss: 0.0258 - val_acc: 0.9899\n",
      "Epoch 9/10\n",
      "150/156 [===========================>..] - ETA: 0s - loss: 0.0686 - acc: 0.9800Epoch 1/10\n",
      "156/156 [==============================] - 2s 10ms/step - loss: 0.0685 - acc: 0.9800 - val_loss: 0.0432 - val_acc: 0.9899\n",
      "Epoch 10/10\n",
      "149/156 [===========================>..] - ETA: 0s - loss: 0.0684 - acc: 0.9797Epoch 1/10\n",
      "156/156 [==============================] - 2s 10ms/step - loss: 0.0712 - acc: 0.9794 - val_loss: 0.0417 - val_acc: 0.9889\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(trainGen, \n",
    "                              steps_per_epoch = trainGen.__len__(), \n",
    "                              verbose=1, \n",
    "                              epochs=epochs,\n",
    "                              workers=4,\n",
    "                              callbacks = [schedule, swa], validation_data = testGen,\n",
    "                              validation_steps = testGen.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b6ece8a-491a-4630-adfc-eddd87f568a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-01T11:09:34.261957Z",
     "iopub.status.busy": "2024-10-01T11:09:34.261737Z",
     "iopub.status.idle": "2024-10-01T11:09:34.303940Z",
     "shell.execute_reply": "2024-10-01T11:09:34.303351Z",
     "shell.execute_reply.started": "2024-10-01T11:09:34.261930Z"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(output_dir):\n",
    "    run(\"mkdir -p {}\".format(output_dir), shell=True)\n",
    "model.save_weights(output_dir + \"/weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0169ac83-8f56-406c-8b3a-6236d03b729e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-01T11:09:40.169346Z",
     "iopub.status.busy": "2024-10-01T11:09:40.169116Z",
     "iopub.status.idle": "2024-10-01T11:09:40.173324Z",
     "shell.execute_reply": "2024-10-01T11:09:40.172727Z",
     "shell.execute_reply.started": "2024-10-01T11:09:40.169318Z"
    }
   },
   "outputs": [],
   "source": [
    "if use_bias:\n",
    "    conv_weights, conv_bias = model.get_layer(\"shared_conv\").get_weights()\n",
    "else:\n",
    "    conv_weights = model.get_layer(\"shared_conv\").get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cbb2eb1b-a444-4724-aecd-bb96639605ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-01T11:09:45.658891Z",
     "iopub.status.busy": "2024-10-01T11:09:45.658697Z",
     "iopub.status.idle": "2024-10-01T11:09:49.669622Z",
     "shell.execute_reply": "2024-10-01T11:09:49.668904Z",
     "shell.execute_reply.started": "2024-10-01T11:09:45.658865Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.997781}\n"
     ]
    }
   ],
   "source": [
    "AUCs = {}\n",
    "nSteps = 500\n",
    "from sklearn.metrics import roc_auc_score\n",
    "for i in range(n_motifs):\n",
    "    tmp_conv_weights = np.zeros(conv_weights.shape)\n",
    "    if use_bias:\n",
    "        tmp_bias = np.zeros(n_motifs)\n",
    "    tmp_conv_weights[:,:,i] = conv_weights[:,:,i]\n",
    "    \n",
    "    if use_bias:\n",
    "        tmp_bias[i] = conv_bias[i]\n",
    "    \n",
    "    if use_bias:\n",
    "        model.get_layer(\"shared_conv\").set_weights([tmp_conv_weights, tmp_bias])\n",
    "    else:\n",
    "        model.get_layer(\"shared_conv\").set_weights([tmp_conv_weights])\n",
    "    yPred = model.predict(testGen, steps=nSteps)\n",
    "    yTest = np.array(nSteps*([1 for i in range(16)] + [0 for i in range(16)]))\n",
    "    AUCs[i] = roc_auc_score(yTest, yPred)\n",
    "print(AUCs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6179085b-d928-4ea8-9e08-fb50b6f3892f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-01T11:09:55.604058Z",
     "iopub.status.busy": "2024-10-01T11:09:55.603851Z",
     "iopub.status.idle": "2024-10-01T11:09:55.690483Z",
     "shell.execute_reply": "2024-10-01T11:09:55.689871Z",
     "shell.execute_reply.started": "2024-10-01T11:09:55.604025Z"
    }
   },
   "outputs": [],
   "source": [
    "scan_model = construct_scan_model(conv_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3bf09d91-d1f4-4c73-9ff1-a03a9df0e766",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-01T11:10:03.184744Z",
     "iopub.status.busy": "2024-10-01T11:10:03.184532Z",
     "iopub.status.idle": "2024-10-01T11:20:38.545978Z",
     "shell.execute_reply": "2024-10-01T11:20:38.545294Z",
     "shell.execute_reply.started": "2024-10-01T11:10:03.184719Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206609/206609 [10:35<00:00, 325.28it/s]\n"
     ]
    }
   ],
   "source": [
    "anr = False\n",
    "thresh = 0\n",
    "random.shuffle(seqs)\n",
    "with open(output_dir + \"/motifs.bed\", \"w\") as f:\n",
    "    for i in tqdm.trange(len(seqs)):\n",
    "        seq = seqs[i]\n",
    "        chrom = \"seq_\" + str(i)\n",
    "        start = 1\n",
    "        stop = len(seq)\n",
    "        encoded_seq = np.vstack((0.25*np.ones((w,4)), encode_sequence(seq), 0.25*np.ones((w,4))))\n",
    "        encoded_seq_rc = encoded_seq[::-1,::-1]\n",
    "\n",
    "        conv_for = scan_model.predict(np.expand_dims(encoded_seq, axis = 0), verbose=0)[0]\n",
    "        conv_rc = scan_model.predict(np.expand_dims(encoded_seq_rc, axis = 0), verbose=0)[0]\n",
    "\n",
    "        for k in range(n_motifs):\n",
    "            if anr:\n",
    "                matches_for = np.argwhere(conv_for[:,k] > thresh)[:,0].tolist()\n",
    "                matches_rc = np.argwhere(conv_rc[:,k] > thresh)[:,0].tolist()\n",
    "                for x in matches_for:\n",
    "                    motif_start = x - w \n",
    "                    motif_end = motif_start + w\n",
    "                    score = conv_for[x,k]\n",
    "                    pfms[k] += encoded_seq[x:x+w,:]\n",
    "\n",
    "                for x in matches_rc:\n",
    "                    motif_end = x + w\n",
    "                    motif_start = motif_end - w \n",
    "                    score = conv_rc[x,k] \n",
    "                    pfms[k] += encoded_seq_rc[x:x+w,:]\n",
    "                    n_instances[k] += 1\n",
    "                \n",
    "            else:\n",
    "                maxFor = np.max(conv_for[:,k])\n",
    "                maxRC = np.max(conv_rc[:,k])\n",
    "\n",
    "                if maxFor > thresh or maxRC > thresh:\n",
    "                    if maxFor > maxRC:\n",
    "                        x = np.argmax(conv_for[:,k])\n",
    "                        motif_start = x - w \n",
    "                        motif_end = motif_start + w\n",
    "                        score = conv_for[x,k]\n",
    "                        motifSeq = decode_sequence(encoded_seq[x:x+w,:])\n",
    "                        print(chrom, start+motif_start, start+motif_end, k, score, \"+\", motifSeq, seq, file=f, sep=\"\\t\")\n",
    "                    else:\n",
    "                        x = np.argmax(conv_rc[:,k])\n",
    "                        motif_end = x + w\n",
    "                        motif_start = motif_end - w \n",
    "                        score = conv_rc[x,k] \n",
    "                        motifSeq = decode_sequence(encoded_seq_rc[x:x+w,:])\n",
    "                        print(chrom, stop-motif_start, stop-motif_start+w, k, score, \"-\", motifSeq, seq, file=f, sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40919af0-b641-499b-8a5b-08819eb5b3f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-01T11:20:38.547436Z",
     "iopub.status.busy": "2024-10-01T11:20:38.547247Z",
     "iopub.status.idle": "2024-10-01T11:20:45.733627Z",
     "shell.execute_reply": "2024-10-01T11:20:45.733021Z",
     "shell.execute_reply.started": "2024-10-01T11:20:38.547408Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(output_dir + \"/motifs.bed\", sep=\"\\t\", names=[\"chrom\", \"start\", \"stop\", \"kernel\", \"score\", \"strand\", \"seq\", \"og_seq\"])\n",
    "df[\"auc\"] = df.kernel.map(AUCs)\n",
    "df.to_csv(output_dir + \"/motifs.txt.gz\", sep=\"\\t\", header=True, index=False)\n",
    "os.remove(output_dir + \"/motifs.bed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13c73e4b-77e8-4845-8532-6fca12272889",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-01T11:20:45.735088Z",
     "iopub.status.busy": "2024-10-01T11:20:45.734905Z",
     "iopub.status.idle": "2024-10-01T11:20:48.849652Z",
     "shell.execute_reply": "2024-10-01T11:20:48.849004Z",
     "shell.execute_reply.started": "2024-10-01T11:20:45.735062Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(4,4, figsize=(20,8), tight_layout=True)\n",
    "for plot_i, i in enumerate(np.argsort(list(AUCs.values()))[::-1]):\n",
    "    n = df[df[\"kernel\"] == i].shape[0]\n",
    "    if n > 0:\n",
    "        auc = AUCs[i]\n",
    "        ax = axes.flatten()[plot_i]\n",
    "        ppm = logomaker.alignment_to_matrix(df[df[\"kernel\"] == i].seq, to_type=\"counts\")\n",
    "        for nuc in [\"A\", \"C\", \"G\", \"T\"]:\n",
    "            if nuc not in ppm.columns:\n",
    "                ppm[nuc] = 0.0\n",
    "        ppm = ppm[[\"A\", \"C\", \"G\", \"T\"]]\n",
    "        ppm = ppm.div(ppm.sum(axis=1), axis=0)\n",
    "        logomaker.Logo(ppm.applymap(get_information_content), ax=ax)\n",
    "        ax.set_ylim([0,2])\n",
    "        ax.set_title(\"Kernel {0}; N = {1}; auROC = {2:.2f}\".format(i, n, auc))\n",
    "    else:\n",
    "        ax = axes.flatten()[plot_i]\n",
    "        fig.delaxes(ax)\n",
    "        \n",
    "for i in range(n_motifs, 16):\n",
    "    fig.delaxes(axes.flatten()[i])\n",
    "plt.savefig(output_dir + \"/logos.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7186db88-2c8f-4830-b2da-f614fd41f1d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
